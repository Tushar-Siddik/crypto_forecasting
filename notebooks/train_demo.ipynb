{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f93b276",
   "metadata": {},
   "source": [
    "Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226334c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure src folder is importable\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Auto-reload changes in .py files\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a3ab7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0a4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.models.train import TimeSeriesTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01db35f",
   "metadata": {},
   "source": [
    "Initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae811d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Choose model type: 'lstm' or 'transformer'\n",
    "model_type = 'lstm'  # or 'transformer'\n",
    "\n",
    "trainer = TimeSeriesTrainer(model_type=model_type)\n",
    "print(\"Device:\", trainer.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a79591",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b121d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw\\BTC-USD_2024-01-15_2026-01-14.csv\n",
      "Number of features: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\ta\\trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "j:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\ta\\trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    }
   ],
   "source": [
    "# Specify cryptocurrency ticker and sequence length\n",
    "ticker = 'BTC-USD'\n",
    "sequence_length = 60\n",
    "\n",
    "train_loader, val_loader, test_loader, feature_scaler, target_scaler, feature_cols = trainer.prepare_data(\n",
    "    ticker=ticker,\n",
    "    sequence_length=sequence_length,\n",
    "    test_size=0.2,\n",
    "    val_size=0.2\n",
    ")\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4e3a9",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a897da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (rnn): LSTM(27, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = len(feature_cols)\n",
    "output_size = 1\n",
    "\n",
    "# LSTM-specific parameters\n",
    "model_params = {\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.2,\n",
    "    'bidirectional': False,\n",
    "    'use_gru': False\n",
    "}\n",
    "\n",
    "# Transformer-specific parameters\n",
    "transformer_params = {\n",
    "    'd_model': 64,\n",
    "    'nhead': 4,\n",
    "    'num_encoder_layers': 2,\n",
    "    'dim_feedforward': 128,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "if model_type == 'lstm':\n",
    "    model = trainer.build_model(input_size=input_size, output_size=output_size, **model_params)\n",
    "else:\n",
    "    model = trainer.build_model(input_size=input_size, output_size=output_size, **transformer_params)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be5c29",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4468df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "j:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "j:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - 0.56s - train_loss: 0.107378 - val_loss: 0.096852\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# adjust as needed\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/best_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m     12\u001b[39m trainer.plot_history()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mj:\\Data Science\\crypto_forecasting\\src\\models\\train.py:217\u001b[39m, in \u001b[36mTimeSeriesTrainer.train\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, lr, patience, save_path)\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m save_path:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mj:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    967\u001b[39m         _save(\n\u001b[32m    968\u001b[39m             obj,\n\u001b[32m    969\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m             _disable_byteorder_record,\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mj:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\serialization.py:828\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mj:\\Data Science\\crypto_forecasting\\venv\\Lib\\site-packages\\torch\\serialization.py:792\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    786\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    787\u001b[39m             \u001b[38;5;28mself\u001b[39m.file_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=50,       # adjust as needed\n",
    "    lr=0.001,\n",
    "    patience=5,\n",
    "    save_path=f'models/best_{model_type}.pth'\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c0114",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076939df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, predictions, actuals = trainer.evaluate(test_loader, target_scaler=target_scaler)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "trainer.plot_predictions(actuals, predictions, n=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b99bf",
   "metadata": {},
   "source": [
    "Quick inference on latest data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47909920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch latest 30-day sequence\n",
    "import pandas as pd\n",
    "from src.data.data_loader import CryptoDataLoader\n",
    "from src.data.feature_engineering import FeatureEngineer\n",
    "\n",
    "loader = CryptoDataLoader()\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "latest_data = loader.get_latest_data(ticker, days=sequence_length)\n",
    "latest_features = engineer.add_technical_indicators(latest_data)\n",
    "\n",
    "# Normalize features\n",
    "latest_features_scaled = feature_scaler.transform(latest_features[feature_cols])\n",
    "latest_seq = np.expand_dims(latest_features_scaled, axis=0)  # shape: [1, seq_len, n_features]\n",
    "\n",
    "latest_seq_tensor = torch.tensor(latest_seq, dtype=torch.float32).to(trainer.device)\n",
    "\n",
    "trainer.model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = trainer.model(latest_seq_tensor)\n",
    "    prediction_value = target_scaler.inverse_transform(prediction.cpu().numpy().reshape(-1,1))\n",
    "    print(f\"Predicted next Close for {ticker}: {prediction_value[0,0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
