{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a39459a",
   "metadata": {},
   "source": [
    "Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure src folder is importable\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Auto-reload changes in .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caff4b",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68716ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import uvicorn\n",
    "\n",
    "from src.data.data_loader import CryptoDataLoader\n",
    "from src.data.feature_engineering import FeatureEngineer\n",
    "from src.models.lstm import LSTMModel\n",
    "from src.models.transformer import TransformerModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac03a69",
   "metadata": {},
   "source": [
    "Initialize API app and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(\n",
    "    title=\"Crypto Price Forecasting API\",\n",
    "    description=\"API for forecasting cryptocurrency prices\"\n",
    ")\n",
    "\n",
    "# Global variables\n",
    "model = None\n",
    "feature_scaler = None\n",
    "target_scaler = None\n",
    "feature_cols = None\n",
    "sequence_length = 60\n",
    "model_type = 'lstm'\n",
    "input_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ebfa9",
   "metadata": {},
   "source": [
    "Define request/response schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a19dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionRequest(BaseModel):\n",
    "    ticker: str\n",
    "    days: int = 1\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    ticker: str\n",
    "    predictions: List[float]\n",
    "    dates: List[str]\n",
    "\n",
    "class ModelInfo(BaseModel):\n",
    "    model_type: str\n",
    "    input_size: int\n",
    "    sequence_length: int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6b57b",
   "metadata": {},
   "source": [
    "Load model (startup simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate loading a model (weights not loaded in this notebook)\n",
    "def load_model():\n",
    "    global model, feature_scaler, target_scaler, feature_cols, sequence_length, model_type, input_size\n",
    "    \n",
    "    model_type = 'lstm'  # or 'transformer'\n",
    "    sequence_length = 60\n",
    "    input_size = 20  # Number of features\n",
    "\n",
    "    if model_type == 'lstm':\n",
    "        model = LSTMModel(\n",
    "            input_size=input_size,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            output_size=1,\n",
    "            dropout=0.2\n",
    "        )\n",
    "    else:\n",
    "        model = TransformerModel(\n",
    "            input_size=input_size,\n",
    "            d_model=64,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=2,\n",
    "            dim_feedforward=128,\n",
    "            output_size=1\n",
    "        )\n",
    "    \n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Dummy feature columns\n",
    "    feature_cols = [f'feature_{i}' for i in range(input_size)]\n",
    "\n",
    "load_model()\n",
    "print(f\"Loaded {model_type} model with input size {input_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e58eb",
   "metadata": {},
   "source": [
    "Root endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Crypto Price Forecasting API\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063db98",
   "metadata": {},
   "source": [
    "Model info endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/model/info\", response_model=ModelInfo)\n",
    "async def get_model_info():\n",
    "    return ModelInfo(\n",
    "        model_type=model_type,\n",
    "        input_size=input_size,\n",
    "        sequence_length=sequence_length\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77bbc49",
   "metadata": {},
   "source": [
    "Prediction endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "async def predict(request: PredictionRequest):\n",
    "    if model is None:\n",
    "        raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
    "    \n",
    "    # Load crypto data\n",
    "    loader = CryptoDataLoader()\n",
    "    data = loader.get_latest_data(request.ticker, days=sequence_length + 10)\n",
    "    \n",
    "    if data is None or len(data) < sequence_length:\n",
    "        raise HTTPException(status_code=404, detail=f\"Insufficient data for {request.ticker}\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    engineer = FeatureEngineer()\n",
    "    data_with_features = engineer.add_technical_indicators(data)\n",
    "    \n",
    "    # Use last sequence_length rows\n",
    "    last_sequence = data_with_features.iloc[-sequence_length:]\n",
    "    features = last_sequence.values\n",
    "    \n",
    "    # Create input tensor\n",
    "    input_tensor = torch.FloatTensor(features).unsqueeze(0)  # batch dimension\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prediction = output.item()\n",
    "    \n",
    "    # Generate future dates\n",
    "    last_date = data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date, periods=request.days + 1, freq='D')[1:]\n",
    "    predictions = [prediction] * request.days\n",
    "    \n",
    "    return PredictionResponse(\n",
    "        ticker=request.ticker,\n",
    "        predictions=predictions,\n",
    "        dates=future_dates.strftime('%Y-%m-%d').tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260bbfb7",
   "metadata": {},
   "source": [
    "Run API server from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to run the API in the notebook (blocking)\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1879e",
   "metadata": {},
   "source": [
    "⚠️ Note: Running uvicorn.run() in a notebook is blocking, so typically you run it in a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd360c26",
   "metadata": {},
   "source": [
    "Test prediction interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "response = client.post(\"/predict\", json={\"ticker\": \"BTC-USD\", \"days\": 3})\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
