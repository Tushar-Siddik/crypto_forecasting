{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f93b276",
   "metadata": {},
   "source": [
    "Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226334c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure src folder is importable\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Auto-reload changes in .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a3ab7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.models.train import TimeSeriesTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01db35f",
   "metadata": {},
   "source": [
    "Initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae811d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model type: 'lstm' or 'transformer'\n",
    "model_type = 'lstm'  # or 'transformer'\n",
    "\n",
    "trainer = TimeSeriesTrainer(model_type=model_type)\n",
    "print(\"Device:\", trainer.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a79591",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify cryptocurrency ticker and sequence length\n",
    "ticker = 'BTC-USD'\n",
    "sequence_length = 60\n",
    "\n",
    "train_loader, val_loader, test_loader, feature_scaler, target_scaler, feature_cols = trainer.prepare_data(\n",
    "    ticker=ticker,\n",
    "    sequence_length=sequence_length,\n",
    "    test_size=0.2,\n",
    "    val_size=0.2\n",
    ")\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4e3a9",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a897da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(feature_cols)\n",
    "output_size = 1\n",
    "\n",
    "# LSTM-specific parameters\n",
    "model_params = {\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.2,\n",
    "    'bidirectional': False,\n",
    "    'use_gru': False\n",
    "}\n",
    "\n",
    "# Transformer-specific parameters\n",
    "transformer_params = {\n",
    "    'd_model': 64,\n",
    "    'nhead': 4,\n",
    "    'num_encoder_layers': 2,\n",
    "    'dim_feedforward': 128,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "if model_type == 'lstm':\n",
    "    model = trainer.build_model(input_size=input_size, output_size=output_size, **model_params)\n",
    "else:\n",
    "    model = trainer.build_model(input_size=input_size, output_size=output_size, **transformer_params)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be5c29",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4468df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=50,       # adjust as needed\n",
    "    lr=0.001,\n",
    "    patience=5,\n",
    "    save_path=f'models/best_{model_type}.pth'\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c0114",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076939df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, predictions, actuals = trainer.evaluate(test_loader, target_scaler=target_scaler)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "trainer.plot_predictions(actuals, predictions, n=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b99bf",
   "metadata": {},
   "source": [
    "Quick inference on latest data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47909920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch latest 30-day sequence\n",
    "import pandas as pd\n",
    "from src.data.data_loader import CryptoDataLoader\n",
    "from src.data.feature_engineering import FeatureEngineer\n",
    "\n",
    "loader = CryptoDataLoader()\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "latest_data = loader.get_latest_data(ticker, days=sequence_length)\n",
    "latest_features = engineer.add_technical_indicators(latest_data)\n",
    "\n",
    "# Normalize features\n",
    "latest_features_scaled = feature_scaler.transform(latest_features[feature_cols])\n",
    "latest_seq = np.expand_dims(latest_features_scaled, axis=0)  # shape: [1, seq_len, n_features]\n",
    "\n",
    "latest_seq_tensor = torch.tensor(latest_seq, dtype=torch.float32).to(trainer.device)\n",
    "\n",
    "trainer.model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = trainer.model(latest_seq_tensor)\n",
    "    prediction_value = target_scaler.inverse_transform(prediction.cpu().numpy().reshape(-1,1))\n",
    "    print(f\"Predicted next Close for {ticker}: {prediction_value[0,0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
